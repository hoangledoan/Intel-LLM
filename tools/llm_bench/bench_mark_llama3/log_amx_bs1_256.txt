<frozen importlib.util>:208: DeprecationWarning: The `openvino.runtime` module is deprecated and will be removed in the 2026.0 release. Please replace `openvino.runtime` with `openvino`.
[ INFO ] ==SUCCESS FOUND==: use_case: text_gen, model_type: llama
[ INFO ] OV Config={'INFERENCE_NUM_THREADS': 160, 'CACHE_DIR': ''}
[ WARNING ] It is recommended to set the environment variable OMP_WAIT_POLICY to PASSIVE, so that OpenVINO inference can use all CPU resources without waiting.
[ INFO ] The num_beams is 1, update Torch thread num from 80 to 16, avoid to use the CPU cores for OpenVINO inference.
[ INFO ] Model path=models/llama-3-8b-int8, openvino runtime version: 2025.0.0-17942-1f68be9f594-releases/2025/0
[ INFO ] Selected OpenVINO GenAI for benchmarking
[ INFO ] Pipeline initialization time: 2.75s
[ INFO ] Numbeams: 1, benchmarking iter nums(exclude warm-up): 3, prompt nums: 1, prompt idx: [0]
[ INFO ] [warm-up][P0] Input text: It is done, and submitted. You can play 'Survival of the Tastiest' on Android, and on the web. Playing on the web works, but you have to simulate multiple touch for table moving and that can be a bit confusing. There is a lot I'd like to talk about. I will go through every topic, insted of making the typical what went right/wrong list. Concept Working over the theme was probably one of the hardest tasks which I had to face. Originally, I had an idea of what kind of game I wanted to develop, gameplay wise - something with a lot of enemies/actors, simple graphics, maybe set in space, controlled from a top-down view. I was confident that I could fit any theme around it. In the end, the problem with a theme like 'Evolution' in a game is that evolution is unassisted. It happens through several seemingly random mutations over time, with the most apt permutation surviving. This genetic car simulator is, in my opinion, a great example of actual evolution of a species facing a challenge. But is it a game? In a game, you need to control something to reach an objective
[ WARNING ] Enabled input prompt permutations. It means that generated results may vary on different steps. If it is not expected, please specify --disable_prompt_permutation in your benchmarking command to disable this behavior
[ INFO ] [warm-up][P0] Input token size: 240, Output size: 128, Infer count: 128, Tokenization Time: 4.86ms, Detokenization Time: 1.43ms, Generation Time: 12.72s, Latency: 99.40 ms/token
[ INFO ] [warm-up][P0] First token latency: 5537.02 ms/token, other tokens latency: 56.58 ms/token, len of tokens: 128 * 1
[ INFO ] [warm-up][P0] First infer latency: 5536.89 ms/infer, other infers latency: 56.31 ms/infer, inference count: 128
[ INFO ] [warm-up][P0] Result MD5:['ddd758b53dea14177d532e1f307e77b4']
[ INFO ] [warm-up][P0] Generated: . In this case, the objective is to survive. But how do you control evolution? You can't. You can only control the environment. So, I had to come up with a way to control evolution. I decided to go with a'survival of the fittest' approach. The fittest being the tastiest. I thought that this would be a good way to control evolution, because it would be a good way to control the environment. I thought that this would be a good way to control evolution, because it would be a good way to control the environment. I thought that this would be a good way to
[ INFO ] [warm-up][P0] start: 2025-03-23T01:21:33.761738, end: 2025-03-23T01:21:46.493238
[ WARNING ] Enabled input prompt permutations. It means that generated results may vary on different steps. If it is not expected, please specify --disable_prompt_permutation in your benchmarking command to disable this behavior
[ INFO ] [1][P0] Input token size: 240, Output size: 128, Infer count: 128, Tokenization Time: 2.33ms, Detokenization Time: 0.78ms, Generation Time: 7.39s, Latency: 57.77 ms/token
[ INFO ] [1][P0] First token latency: 203.59 ms/token, other tokens latency: 56.62 ms/token, len of tokens: 128 * 1
[ INFO ] [1][P0] First infer latency: 203.52 ms/infer, other infers latency: 56.35 ms/infer, inference count: 128
[ INFO ] [1][P0] Result MD5:['89e8111277ab7e5ef4a5ce404e9376dc']
[ INFO ] [1][P0] Generated: . In this case, the objective is to survive. But how do you control evolution? You can't. You can only control the environment, and hope that the species will adapt. This is not a game. It is a simulation. I had to think of something else. I had to think of something that would be a game, but would also fit the theme. I had to think of something that would be a game, but would also fit the theme. I had to think of something that would be a game, but would also fit the theme. I had to think of something that would be a game, but would also
[ INFO ] [1][P0] start: 2025-03-23T01:21:46.493690, end: 2025-03-23T01:21:53.891798
[ WARNING ] Enabled input prompt permutations. It means that generated results may vary on different steps. If it is not expected, please specify --disable_prompt_permutation in your benchmarking command to disable this behavior
[ INFO ] [2][P0] Input token size: 240, Output size: 128, Infer count: 128, Tokenization Time: 1.28ms, Detokenization Time: 0.79ms, Generation Time: 7.36s, Latency: 57.53 ms/token
[ INFO ] [2][P0] First token latency: 195.77 ms/token, other tokens latency: 56.44 ms/token, len of tokens: 128 * 1
[ INFO ] [2][P0] First infer latency: 195.71 ms/infer, other infers latency: 56.13 ms/infer, inference count: 128
[ INFO ] [2][P0] Result MD5:['7a51c6f4953bc4b38c29dcd0ae2c8754']
[ INFO ] [2][P0] Generated: . You need to have a goal. You need to have a challenge. You need to have a reward. You need to have a way to fail. You need to have a way to succeed. You need to have a way to progress. You need to have a way to go back. You need to have a way to restart. You need to have a way to pause. You need to have a way to save. You need to have a way to load. You need to have a way to quit. You need to have a way to cheat. You need to have a way to win. You need to have a way
[ INFO ] [2][P0] start: 2025-03-23T01:21:53.892098, end: 2025-03-23T01:22:01.258602
[ WARNING ] Enabled input prompt permutations. It means that generated results may vary on different steps. If it is not expected, please specify --disable_prompt_permutation in your benchmarking command to disable this behavior
[ INFO ] [3][P0] Input token size: 240, Output size: 128, Infer count: 128, Tokenization Time: 1.37ms, Detokenization Time: 0.94ms, Generation Time: 7.40s, Latency: 57.80 ms/token
[ INFO ] [3][P0] First token latency: 193.83 ms/token, other tokens latency: 56.72 ms/token, len of tokens: 128 * 1
[ INFO ] [3][P0] First infer latency: 193.77 ms/infer, other infers latency: 56.41 ms/infer, inference count: 128
[ INFO ] [3][P0] Result MD5:['dad7aec85ceafaadd4f6f0d9363d1e48']
[ INFO ] [3][P0] Generated: . You need to have a goal. You need to have a challenge. You need to have a reward. You need to have a punishment. You need to have a way to fail. You need to have a way to succeed. You need to have a way to win. You need to have a way to lose. You need to have a way to cheat. You need to have a way to be cheated. You need to have a way to be cheated by a cheater. You need to have a way to cheat a cheater. You need to have a way to cheat a cheater who cheats. You need to have
[ INFO ] [3][P0] start: 2025-03-23T01:22:01.258930, end: 2025-03-23T01:22:08.660241
[ INFO ] <<< Warm-up iteration is excluded. >>>
[ INFO ] [Total] Iterations: 3
[ INFO ] [Average] P[0] Input token size: 240, 1st token latency: 197.73 ms/token, 2nd token latency: 56.59 ms/token, 2nd tokens throughput: 17.67 tokens/s
/home/hoang-std/openvino_distributed/openvino.genai/tools/llm_bench/energy.py:10: DtypeWarning: Columns (2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,88,89,90,91,96,97,98,99,104,105,106,107,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv("/home/hoang-std/pcm/build/bin/int8_llama-2-7b-chat-hf.csv")
Total energy: 8162.23
Power consumption: 583.0164285714285
